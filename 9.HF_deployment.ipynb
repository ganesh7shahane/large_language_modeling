{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment using gradio and HF Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.utils import logging\n",
    "\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the pipeline object from transformers and gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"image-to-text\",\n",
    "                model=\"Salesforce/blip-image-captioning-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to take the input, call the pipeline and return the generated text from the output\n",
    "\n",
    "def launch(input):\n",
    "    out = pipe(input)\n",
    "    return out[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the gradio interface, input being the gradio.image and output is the text :\n",
    "\n",
    "iface = gr.Interface(launch,\n",
    "                     inputs=gr.Image(type='pil'),\n",
    "                     outputs=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://c55d7d2b036d251d23.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://c55d7d2b036d251d23.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ganeshshahane/.pyenv/versions/3.10.0/envs/rdkit310/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "iface.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying this model on Hugging Face Spaces\n",
    "\n",
    "Once we confirm the the app works locally, we can now deploy it on the cloud for everyone to access.\n",
    "\n",
    "Towards this, we simply copy-paste the above code blocks in the app.py file on HF spaces\n",
    "\n",
    "Demo on how to do this: https://www.youtube.com/watch?v=3bSVKNKb_PY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acces the deployed model using API:\n",
    "\n",
    "For this, we need the gradio client installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded as API: https://ganesh7shahane-pilot-api.hf.space âœ”\n",
      "a red bus with a blue stripe on the side\n"
     ]
    }
   ],
   "source": [
    "from gradio_client import Client, file\n",
    "\n",
    "client = Client(\"ganesh7shahane/pilot-api\")\n",
    "result = client.predict(\n",
    "\t\tinput=file('https://raw.githubusercontent.com/gradio-app/gradio/main/test/test_files/bus.png'), #give input image here\n",
    "\t\tapi_name=\"/predict\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client.predict() Usage Info\n",
      "---------------------------\n",
      "Named API endpoints: 1\n",
      "\n",
      " - predict(input, api_name=\"/predict\") -> output\n",
      "    Parameters:\n",
      "     - [Image] input: filepath (required)  \n",
      "    Returns:\n",
      "     - [Textbox] output: str \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To get more information on the API:\n",
    "\n",
    "client.view_api()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives you some information on how to call the api, through ```api_name``` ```predict```. It also gives the expected parameters and the expected output, which would be a string.\n",
    "\n",
    "So perfect. We were able to call our model as an API outside our local machine, so eveything is done on the cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdkit310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
