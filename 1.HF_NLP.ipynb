{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Hugging Face: Natural Language Processing (NLP)\n",
    "\n",
    "To cover the basics, we will import a facebook chatbot from https://huggingface.co/facebook/blenderbot-400M-distill \n",
    "\n",
    "We will then try and converse with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am RDKit version: 2023.09.5\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import rdkit\n",
    "print(f\"I am RDKit version: {rdkit.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "# Use a pipeline as a high-level helper\n",
    "\n",
    "chatbot = pipeline(task=\"conversational\", model=\"facebook/blenderbot-400M-distill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a prompt:\n",
    "user_message = \"\"\"\n",
    "What are some fun activities I can do in the winter?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To pass the user message to the chatbot, we first put it in a conversation object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation id: 7c8856cd-ba29-4434-a06a-4c2f72ac09d4\n",
      "user: \n",
      "What are some fun activities I can do in the winter?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conversation = Conversation(user_message)\n",
    "print(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "No chat template is defined for this tokenizer - using the default template for the BlenderbotTokenizerFast class. If the default is not appropriate for your model, please set `tokenizer.chat_template` to an appropriate template. See https://huggingface.co/docs/transformers/main/chat_templating for more information.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conversation = chatbot(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation id: 7c8856cd-ba29-4434-a06a-4c2f72ac09d4\n",
      "user: \n",
      "What are some fun activities I can do in the winter?\n",
      "\n",
      "assistant:  I like snowboarding and skiing.  What do you like to do in winter?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can continue the conversation with the chatbot with:\n",
    "\n",
    "print(chatbot(Conversation(\"What else do you recommend?\")))\n",
    "\n",
    "However, the chatbot may provide an unrelated response because it does not have memory of any prior conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation id: 7b096a88-2710-4e7c-a477-38f1273657dd\n",
      "user: What else do you recommend?\n",
      "assistant:  Well, I'm not sure what else I can think of, but I do know that I'm going to miss her.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The assistant doesn't remember prior conversation:\n",
    "print(chatbot(Conversation(\"What else do you recommend?\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To include prior conversations in the LLM's context, you can add a 'message' to include the previous chat history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.add_message(\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": \"\"\"\n",
    "What else do you recommend?\n",
    "\"\"\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation id: 7c8856cd-ba29-4434-a06a-4c2f72ac09d4\n",
      "user: \n",
      "What are some fun activities I can do in the winter?\n",
      "\n",
      "assistant:  I like snowboarding and skiing.  What do you like to do in winter?\n",
      "user: \n",
      "What else do you recommend?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer is not very insightful as the model is quite small, only of 400 million parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation id: 7c8856cd-ba29-4434-a06a-4c2f72ac09d4\n",
      "user: \n",
      "What are some fun activities I can do in the winter?\n",
      "\n",
      "assistant:  I like snowboarding and skiing.  What do you like to do in winter?\n",
      "user: \n",
      "What else do you recommend?\n",
      "\n",
      "assistant:  Snowboarding is a lot of fun.  You can do it indoors or outdoors.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conversation = chatbot(conversation)\n",
    "\n",
    "print(conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many state-of-the-art open source models that can do quite well, if you have the hardware to run them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying something else:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation id: 23e0d4f3-be5b-4fee-a6b0-ed46f01da398\n",
      "user: Who is Albert Einstein?\n",
      "assistant:  He was an American astrophysicist. He was born in 1903.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(chatbot(Conversation(\"Who is Albert Einstein?\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdkit310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
